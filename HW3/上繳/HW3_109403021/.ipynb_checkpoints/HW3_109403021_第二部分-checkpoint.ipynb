{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "98621ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第1題\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"customer_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dfbf977d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料筆數： 3083\n",
      "屬性數量： 20\n",
      "\n",
      "每個欄位的空值個數：\n",
      "CustomerID                       0\n",
      "Churn                            0\n",
      "Tenure                         153\n",
      "PreferredLoginDevice             0\n",
      "CityTier                         0\n",
      "WarehouseToHome                154\n",
      "PreferredPaymentMode             0\n",
      "Gender                           0\n",
      "HourSpendOnApp                 150\n",
      "NumberOfDeviceRegistered         0\n",
      "PreferedOrderCat                 0\n",
      "SatisfactionScore                0\n",
      "MaritalStatus                    0\n",
      "NumberOfAddress                  0\n",
      "Complain                         0\n",
      "OrderAmountHikeFromlastYear    131\n",
      "CouponUsed                     126\n",
      "OrderCount                     128\n",
      "DaySinceLastOrder              166\n",
      "CashbackAmount                   0\n",
      "dtype: int64\n",
      "\n",
      "各類別(target)的資料筆數：\n",
      "Churn\n",
      "0    2132\n",
      "1     951\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#第2題\n",
    "print(\"資料筆數：\", len(df))\n",
    "print(\"屬性數量：\", len(df.columns))\n",
    "print(\"\\n每個欄位的空值個數：\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n各類別(target)的資料筆數：\")\n",
    "print(df.groupby('Churn').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57787038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩餘資料筆數： 3078\n"
     ]
    }
   ],
   "source": [
    "#第3題\n",
    "df.drop_duplicates(subset=['CustomerID'], keep='first', inplace=True)\n",
    "print(\"剩餘資料筆數：\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "94ea4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第4題\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 使用平均數填補空值(已從第2題找到有空值的欄位)\n",
    "df['Tenure'].fillna(df['Tenure'].mean(), inplace=True)\n",
    "df['WarehouseToHome'].fillna(df['WarehouseToHome'].mean(), inplace=True)\n",
    "df['HourSpendOnApp'].fillna(df['HourSpendOnApp'].mean(), inplace=True)\n",
    "df['OrderAmountHikeFromlastYear'].fillna(df['OrderAmountHikeFromlastYear'].mean(), inplace=True)\n",
    "df['CouponUsed'].fillna(df['CouponUsed'].mean(), inplace=True)\n",
    "df['OrderCount'].fillna(df['OrderCount'].mean(), inplace=True)\n",
    "df['DaySinceLastOrder'].fillna(df['DaySinceLastOrder'].mean(), inplace=True)\n",
    "\n",
    "#把nominal欄位轉換為numeric型態\n",
    "le = LabelEncoder()\n",
    "df = pd.get_dummies(df, columns=['PreferredLoginDevice'])\n",
    "df = pd.get_dummies(df, columns=['PreferredPaymentMode'])\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n",
    "df = pd.get_dummies(df, columns=['PreferedOrderCat'])\n",
    "df = pd.get_dummies(df, columns=['MaritalStatus'])\n",
    "\n",
    "#把預測欄位轉為nominal\n",
    "df['Churn'] = df['Churn'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5f0ece14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第5題\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['CustomerID', 'Churn'], axis=1)\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3e5da7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM訓練集準確率： 0.999535747446611\n",
      "SVM測試集準確率： 0.9069264069264069\n",
      "Logistic Regression訓練集準確率： 0.841225626740947\n",
      "Logistic Regression測試集準確率： 0.8333333333333334\n",
      "Decision Tree訓練集準確率： 0.8700092850510678\n",
      "Decision Tree測試集準確率： 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "#第6題\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#SVM\n",
    "svm = SVC(kernel='rbf', C=5, gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(penalty='l1', C=1, solver='liblinear', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('Logistic Regression訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Logistic Regression測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "#Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=3, max_leaf_nodes=15)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('Decision Tree訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Decision Tree測試集準確率：', accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a4d7f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "比較超參數:C設為1或5\n",
      "  C設為1(訓練集準確度,測試集準確度)： 0.6949860724233984 0.685064935064935\n",
      "  C設為5(訓練集準確度,測試集準確度)： 0.8170844939647168 0.7803030303030303\n",
      "比較超參數:gamma設為scale或auto\n",
      "  gamma設為scale(訓練集準確度,測試集準確度)： 0.6949860724233984 0.685064935064935\n",
      "  gamma設為auto(訓練集準確度,測試集準確度)： 0.6949860724233984 0.685064935064935\n",
      "\n",
      "Logistic Regression\n",
      "比較超參數:C設為1或5\n",
      "  C設為1(訓練集準確度,測試集準確度)： 0.8365831012070566 0.8311688311688312\n",
      "  C設為5(訓練集準確度,測試集準確度)： 0.8375116063138347 0.8300865800865801\n",
      "比較超參數:penalty設為l1或l2\n",
      "  penalty設為l1(訓練集準確度,測試集準確度)： 0.841225626740947 0.8333333333333334\n",
      "  penalty設為l2(訓練集準確度,測試集準確度)： 0.8365831012070566 0.8311688311688312\n",
      "\n",
      "Decision Tree\n",
      "比較超參數:criterion設為設為gini或entropy\n",
      "  criterion設為gini(訓練集準確度,測試集準確度)： 1.0 0.9058441558441559\n",
      "  criterion設為entropy(訓練集準確度,測試集準確度)： 1.0 0.8971861471861472\n",
      "比較超參數:min_samples_split設為2或5\n",
      "  min_samples_split設為2(訓練集準確度,測試集準確度)： 1.0 0.8961038961038961\n",
      "  min_samples_split設為5(訓練集準確度,測試集準確度)： 0.9846796657381616 0.8733766233766234\n"
     ]
    }
   ],
   "source": [
    "#第7題\n",
    "\n",
    "#SVM\n",
    "print('SVM')\n",
    "#比較超參數:C設為1或5\n",
    "print('比較超參數:C設為1或5')\n",
    "svm = SVC(C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('  C設為1(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "svm = SVC(C=5)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('  C設為5(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "#比較超參數:gamma設為scale或auto\n",
    "print('比較超參數:gamma設為scale或auto')\n",
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('  gamma設為scale(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('  gamma設為auto(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print()\n",
    "\n",
    "#Logistic Regression\n",
    "print('Logistic Regression')\n",
    "#比較超參數:C設為設為1或5\n",
    "print('比較超參數:C設為1或5')\n",
    "lr = LogisticRegression(C=1,solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('  C設為1(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "lr = LogisticRegression(C=5,solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('  C設為5(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "#比較超參數:penalty設為l1或l2\n",
    "print('比較超參數:penalty設為l1或l2')\n",
    "lr = LogisticRegression(penalty='l1',solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('  penalty設為l1(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "lr = LogisticRegression(penalty='l2',solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('  penalty設為l2(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "print()\n",
    "\n",
    "#Decision Tree\n",
    "print('Decision Tree')\n",
    "#比較超參數:criterion設為設為gini或entropy\n",
    "print('比較超參數:criterion設為設為gini或entropy')\n",
    "dt = DecisionTreeClassifier(criterion='gini')\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('  criterion設為gini(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('  criterion設為entropy(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "#比較超參數:min_samples_split設為2或5\n",
    "print('比較超參數:min_samples_split設為2或5')\n",
    "dt = DecisionTreeClassifier(min_samples_split=2)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('  min_samples_split設為2(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))\n",
    "dt = DecisionTreeClassifier(min_samples_split=5)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('  min_samples_split設為5(訓練集準確度,測試集準確度)：', accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a206119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM訓練集準確率： 0.999535747446611\n",
      "SVM測試集準確率： 0.9069264069264069\n",
      "Logistic Regression訓練集準確率： 0.841225626740947\n",
      "Logistic Regression測試集準確率： 0.8333333333333334\n",
      "Decision Tree訓練集準確率： 0.8700092850510678\n",
      "Decision Tree測試集準確率： 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "#第8題\n",
    "\n",
    "#重覆第6題\n",
    "#SVM\n",
    "svm = SVC(kernel='rbf', C=5, gamma='auto')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_svm = y_test\n",
    "y_pred_test_svm = y_pred_test\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(penalty='l1', C=1, solver='liblinear', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('Logistic Regression訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Logistic Regression測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_lr = y_test\n",
    "y_pred_test_lr = y_pred_test\n",
    "\n",
    "#Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=3, max_leaf_nodes=15)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('Decision Tree訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Decision Tree測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_dt = y_test\n",
    "y_pred_test_dt = y_pred_test\n",
    "\n",
    "#可以看出在這樣的超參數設定下，SVM無論在訓練集還是測試集都有最高的準確率，而Logistic Regression和 Decision Tree的表現就比較差\n",
    "#但這也不代表SVM最好或最適合這個資料集的預測，不同的超參數調整可能導致3個模型的表現好壞出現變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1bde5f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM：\n",
      " [[600  33]\n",
      " [ 53 238]]\n",
      "\n",
      "Logistic Regression：\n",
      " [[567  66]\n",
      " [ 88 203]]\n",
      "\n",
      "Decision Tree：\n",
      " [[576  57]\n",
      " [ 99 192]]\n"
     ]
    }
   ],
   "source": [
    "#第9題\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#SVM\n",
    "svm_cm = confusion_matrix(y_test_svm, y_pred_test_svm)\n",
    "print(\"SVM：\\n\", svm_cm)\n",
    "print()\n",
    "\n",
    "#Logistic Regression\n",
    "lr_cm = confusion_matrix(y_test_lr, y_pred_test_lr)\n",
    "print(\"Logistic Regression：\\n\", lr_cm)\n",
    "print()\n",
    "\n",
    "# Decision Tree\n",
    "dt_cm = confusion_matrix(y_test_dt, y_pred_test_dt)\n",
    "print(\"Decision Tree：\\n\", dt_cm)\n",
    "\n",
    "\n",
    "#這些混淆矩陣的意義就是可以看出每個模型對於測試集的表現\n",
    "#以SVM為例，矩陣可看出此模型600次預測該顧客不是流失顧客(0)且真的是流失顧客、33次預測該顧客是流失顧客(0)但事實上不是\n",
    "#以及53次預測是流失顧客(1)但預測錯誤、238次預測是流失顧客(1)且預測正確\n",
    "#其他模型以此類推"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d789e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_svm = y_test\n",
    "y_pred_test_svm = y_pred_test\n",
    "\n",
    "#Logistic Regression\n",
    "lr = LogisticRegression(penalty='l1', C=1, solver='liblinear', max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('Logistic Regression訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Logistic Regression測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_lr = y_test\n",
    "y_pred_test_lr = y_pred_test\n",
    "\n",
    "#Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=3, max_leaf_nodes=15)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('Decision Tree訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('Decision Tree測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "y_test_dt = y_test\n",
    "y_pred_test_dt = y_pred_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
