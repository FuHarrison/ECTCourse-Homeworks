{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863b3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第1題\n",
    "import pandas as pd\n",
    "data = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32b36ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#第2題\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#檢查是否有缺失值(發現所有屬性缺失數皆為0)\n",
    "print(data.isnull().sum())\n",
    "\n",
    "#把nominal欄位轉換為numeric型態\n",
    "le = LabelEncoder()\n",
    "data['sex'] = le.fit_transform(data['sex'])\n",
    "data['smoker'] = le.fit_transform(data['smoker'])\n",
    "data = pd.get_dummies(data, columns=['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb85fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第3題\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['charges'], axis=1)\n",
    "y = data['charges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)#這邊將訓練集和測試集劃分為8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f5560e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16164\\1229967702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM訓練集準確率：'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM測試集準確率：'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous is not supported"
     ]
    }
   ],
   "source": [
    "#第4題\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test = lr.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "# SVM (SVR)\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred_train = svr.predict(X_train)\n",
    "y_pred_test = svr.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_train = dt.predict(X_train)\n",
    "y_pred_test = dt.predict(X_test)\n",
    "print('SVM訓練集準確率：', accuracy_score(y_train, y_pred_train))\n",
    "print('SVM測試集準確率：', accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1b0d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集表現:\n",
      "Linear Regression: R2 = 0.7417    , RMSE = 6105.5452 , MAE = 4208.2346 \n",
      "SVR              : R2 = -0.0978   , RMSE = 12587.6298, MAE = 8246.6707 \n",
      "Decision Tree    : R2 = 0.9983    , RMSE = 494.2060  , MAE = 29.5725   \n",
      "\n",
      "測試資料集表現:\n",
      "Linear Regression: R2 = 0.7836    , RMSE = 5796.2847 , MAE = 4181.1945 \n",
      "SVR              : R2 = -0.0725   , RMSE = 12903.3834, MAE = 8597.6931 \n",
      "Decision Tree    : R2 = 0.6932    , RMSE = 6901.9999 , MAE = 3346.8004 \n"
     ]
    }
   ],
   "source": [
    "#第5題\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#訓練資料集表現\n",
    "print('訓練資料集表現:')\n",
    "print('Linear Regression: R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_train, lr.predict(X_train)),\n",
    "    np.sqrt(mean_squared_error(y_train, lr.predict(X_train))),\n",
    "    mean_absolute_error(y_train, lr.predict(X_train))\n",
    "))\n",
    "print('SVR              : R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_train, svr.predict(X_train)),\n",
    "    np.sqrt(mean_squared_error(y_train, svr.predict(X_train))),\n",
    "    mean_absolute_error(y_train, svr.predict(X_train))\n",
    "))\n",
    "print('Decision Tree    : R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_train, dt.predict(X_train)),\n",
    "    np.sqrt(mean_squared_error(y_train, dt.predict(X_train))),\n",
    "    mean_absolute_error(y_train, dt.predict(X_train))\n",
    "))\n",
    "\n",
    "print()\n",
    "\n",
    "#測試資料集表現\n",
    "print('測試資料集表現:')\n",
    "print('Linear Regression: R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_test, lr.predict(X_test)),\n",
    "    np.sqrt(mean_squared_error(y_test, lr.predict(X_test))),\n",
    "    mean_absolute_error(y_test, lr.predict(X_test))\n",
    "))\n",
    "print('SVR              : R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_test, svr.predict(X_test)),\n",
    "    np.sqrt(mean_squared_error(y_test, svr.predict(X_test))),\n",
    "    mean_absolute_error(y_test, svr.predict(X_test))\n",
    "))\n",
    "print('Decision Tree    : R2 = {:<10.4f}, RMSE = {:<10.4f}, MAE = {:<10.4f}'.format(\n",
    "    r2_score(y_test, dt.predict(X_test)),\n",
    "    np.sqrt(mean_squared_error(y_test, dt.predict(X_test))),\n",
    "    mean_absolute_error(y_test, dt.predict(X_test))\n",
    "))\n",
    "\n",
    "\n",
    "#可以看到輸出結果中，無論是在訓練資料集中還是在測試資料集中，SVR的表現都是最差的(R2為負數、RSME和 MAE最大)\n",
    "#而Linear Regression的表現在測試資料集中較好，Decision Tree則是在訓練資料集中表現較好(有點overfitting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
