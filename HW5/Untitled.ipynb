{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22fe724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取資料集\n",
    "df = pd.read_csv('customer_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcab6b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set size:  3384 , ratio: 60.00%\n",
      "\n",
      "Origin set churn percentage:\n",
      " 0    0.831383\n",
      "1    0.168617\n",
      "Name: Churn, dtype: float64\n",
      "New set churn percentage:\n",
      " 0    0.831265\n",
      "1    0.168735\n",
      "Name: Churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#第1題\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "#取出60%\n",
    "split = StratifiedShuffleSplit(n_splits=1, train_size=0.6, random_state=15)\n",
    "\n",
    "for train_index, test_index in split.split(df, df['Churn']):\n",
    "    new_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]\n",
    "\n",
    "\n",
    "# 檢查分割結果\n",
    "new_set_size = len(new_set)\n",
    "test_set_size = len(test_set)\n",
    "\n",
    "new_set_ratio = new_set_size / (new_set_size + test_set_size)\n",
    "test_set_ratio = test_set_size / (new_set_size + test_set_size)\n",
    "\n",
    "print(\"New set size: \", new_set_size, \", ratio: {:.2%}\".format(new_set_ratio))\n",
    "#print(\"Test set size: \", test_set_size, \", ratio: {:.2%}\".format(test_set_ratio))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "origin_churn_percent = df['Churn'].value_counts(normalize=True)\n",
    "print(\"Origin set churn percentage:\\n\", origin_churn_percent)\n",
    "\n",
    "new_churn_percent = new_set['Churn'].value_counts(normalize=True)\n",
    "print(\"New set churn percentage:\\n\", new_churn_percent)\n",
    "\n",
    "#test_churn_percent = test_set['Churn'].value_counts(normalize=True)\n",
    "#print(\"Test set churn percentage:\\n\", test_churn_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af0c132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2813\n",
      "1     571\n",
      "Name: Churn, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#第2題\n",
    "print(new_set['Churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d6a064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "每個欄位的空值個數：\n",
      "CustomerID                       0\n",
      "Churn                            0\n",
      "Tenure                         154\n",
      "PreferredLoginDevice             0\n",
      "CityTier                         0\n",
      "WarehouseToHome                141\n",
      "PreferredPaymentMode             0\n",
      "Gender                           0\n",
      "HourSpendOnApp                 148\n",
      "NumberOfDeviceRegistered         0\n",
      "PreferedOrderCat                 0\n",
      "SatisfactionScore                0\n",
      "MaritalStatus                    0\n",
      "NumberOfAddress                  0\n",
      "Complain                         0\n",
      "OrderAmountHikeFromlastYear    157\n",
      "CouponUsed                     140\n",
      "OrderCount                     160\n",
      "DaySinceLastOrder              189\n",
      "CashbackAmount                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#第3題\n",
    "print(\"\\n每個欄位的空值個數：\")\n",
    "print(new_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139170e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第3題-續\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 使用平均數填補空值\n",
    "new_set['Tenure'].fillna(new_set['Tenure'].mean(), inplace=True)\n",
    "new_set['WarehouseToHome'].fillna(new_set['WarehouseToHome'].mean(), inplace=True)\n",
    "new_set['HourSpendOnApp'].fillna(new_set['HourSpendOnApp'].mean(), inplace=True)\n",
    "new_set['OrderAmountHikeFromlastYear'].fillna(new_set['OrderAmountHikeFromlastYear'].mean(), inplace=True)\n",
    "new_set['CouponUsed'].fillna(new_set['CouponUsed'].mean(), inplace=True)\n",
    "new_set['OrderCount'].fillna(new_set['OrderCount'].mean(), inplace=True)\n",
    "new_set['DaySinceLastOrder'].fillna(new_set['DaySinceLastOrder'].mean(), inplace=True)\n",
    "\n",
    "#把nominal欄位轉換為numeric型態\n",
    "le = LabelEncoder()\n",
    "new_set = pd.get_dummies(new_set, columns=['PreferredLoginDevice'])\n",
    "new_set = pd.get_dummies(new_set, columns=['PreferredPaymentMode'])\n",
    "new_set['Gender'] = le.fit_transform(new_set['Gender'])\n",
    "new_set = pd.get_dummies(new_set, columns=['PreferedOrderCat'])\n",
    "new_set = pd.get_dummies(new_set, columns=['MaritalStatus'])\n",
    "\n",
    "#把預測欄位轉為nominal\n",
    "new_set['Churn'] = new_set['Churn'].astype('category')\n",
    "\n",
    "#刪掉id欄\n",
    "new_set = new_set.drop('CustomerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2206e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第4題\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "X = new_set.drop(\"Churn\", axis=1)\n",
    "y = new_set[\"Churn\"]\n",
    "\n",
    "# 使用 Logistic Regression 建立模型並評估\n",
    "lr = LogisticRegression(penalty='l1', C=1, solver='liblinear', max_iter=1000)\n",
    "lr_scores = cross_val_score(lr, X, y, cv=10,scoring='accuracy')\n",
    "# print(\"Logistic Regression scores:\")\n",
    "# print(np.array2string(lr_scores, separator='\\n'))\n",
    "# print(\"Mean score:\", lr_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "# 使用 SVM 建立模型並評估\n",
    "svm = SVC(kernel='rbf', C=5, gamma='auto')\n",
    "svm_scores = cross_val_score(svm, X, y, cv=10,scoring='accuracy')\n",
    "# print(\"SVM scores:\")\n",
    "# print(np.array2string(svm_scores, separator='\\n'))\n",
    "# print(\"Mean score:\", svm_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89be6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 10-fold cross-validation scores: [0.87610619 0.90855457 0.89380531 0.89380531 0.8964497  0.89349112\n",
      " 0.8964497  0.84911243 0.89349112 0.90828402]\n",
      "SVM 10-fold cross-validation scores: [0.92625369 0.92035398 0.92035398 0.90560472 0.89053254 0.91715976\n",
      " 0.9260355  0.93786982 0.91420118 0.93491124]\n"
     ]
    }
   ],
   "source": [
    "#第5題\n",
    "\n",
    "# 輸出每個模型的交叉驗證分數\n",
    "print('Logistic Regression 10-fold cross-validation scores:', lr_scores)\n",
    "print('SVM 10-fold cross-validation scores:', svm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ab87da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14056\\2005231586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 對測試集進行預測\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Churn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msvm_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Churn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 計算模型的準確率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mthis\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1222\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# # 對測試集進行預測\n",
    "# lr_pred = lr.predict(test_set.drop('Churn', axis=1))\n",
    "# svm_pred = svm.predict(test_set.drop('Churn', axis=1))\n",
    "\n",
    "# # 計算模型的準確率\n",
    "# lr_acc = accuracy_score(test_set['Churn'], lr_pred)\n",
    "# svm_acc = accuracy_score(test_set['Churn'], svm_pred)\n",
    "\n",
    "# # 印出結果\n",
    "# print(\"Logistic Regression accuracy:\", lr_acc)\n",
    "# print(\"SVM accuracy:\", svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a7ce084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr Average: 0.8909648112268946\n",
      "svm Average: 0.919327643085302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "all_lr_scores = []\n",
    "all_svm_scores = []\n",
    "\n",
    "for i in range(30):\n",
    "    # 假設你的 dataframe 為 df，Churn 欄位名稱為 'Churn'\n",
    "    split = StratifiedShuffleSplit(n_splits=1, train_size=0.6, random_state=15)\n",
    "\n",
    "    for train_index, test_index in split.split(df, df['Churn']):\n",
    "        new_set = df.loc[train_index]\n",
    "        test_set = df.loc[test_index]\n",
    "\n",
    "    # 使用平均數填補空值\n",
    "    new_set['Tenure'].fillna(new_set['Tenure'].mean(), inplace=True)\n",
    "    new_set['WarehouseToHome'].fillna(new_set['WarehouseToHome'].mean(), inplace=True)\n",
    "    new_set['HourSpendOnApp'].fillna(new_set['HourSpendOnApp'].mean(), inplace=True)\n",
    "    new_set['OrderAmountHikeFromlastYear'].fillna(new_set['OrderAmountHikeFromlastYear'].mean(), inplace=True)\n",
    "    new_set['CouponUsed'].fillna(new_set['CouponUsed'].mean(), inplace=True)\n",
    "    new_set['OrderCount'].fillna(new_set['OrderCount'].mean(), inplace=True)\n",
    "    new_set['DaySinceLastOrder'].fillna(new_set['DaySinceLastOrder'].mean(), inplace=True)\n",
    "\n",
    "    #把nominal欄位轉換為numeric型態\n",
    "    le = LabelEncoder()\n",
    "    new_set = pd.get_dummies(new_set, columns=['PreferredLoginDevice'])\n",
    "    new_set = pd.get_dummies(new_set, columns=['PreferredPaymentMode'])\n",
    "    new_set['Gender'] = le.fit_transform(new_set['Gender'])\n",
    "    new_set = pd.get_dummies(new_set, columns=['PreferedOrderCat'])\n",
    "    new_set = pd.get_dummies(new_set, columns=['MaritalStatus'])\n",
    "\n",
    "    #把預測欄位轉為nominal\n",
    "    new_set['Churn'] = new_set['Churn'].astype('category')\n",
    "    \n",
    "    #刪掉id欄\n",
    "    new_set = new_set.drop('CustomerID', axis=1)\n",
    "\n",
    "    X = new_set.drop(\"Churn\", axis=1)\n",
    "    y = new_set[\"Churn\"]\n",
    "\n",
    "    # 使用 Logistic Regression 建立模型並評估\n",
    "    lr = LogisticRegression(penalty='l1', C=1, solver='liblinear', max_iter=1000)\n",
    "    lr_scores = cross_val_score(lr, X, y, cv=10,scoring='accuracy')\n",
    "    all_lr_scores.append(lr_scores.mean())\n",
    "\n",
    "    # 使用 SVM 建立模型並評估\n",
    "    svm = SVC(kernel='rbf', C=5, gamma='auto')\n",
    "    svm_scores = cross_val_score(svm, X, y, cv=10,scoring='accuracy')\n",
    "    all_svm_scores.append(svm_scores.mean())\n",
    "\n",
    "lr_average = sum(all_lr_scores) / len(all_lr_scores)\n",
    "svm_average = sum(all_svm_scores) / len(all_svm_scores)\n",
    "print(\"lr Average:\", lr_average)\n",
    "print(\"svm Average:\", svm_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb261e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR mean: 0.8909648112268944\n",
      "SVM mean: 0.9193276430853018\n",
      "Difference in means: -0.028362831858407378\n",
      "LR std: 5.401603131214479e-05\n",
      "SVM std: 3.387607712450221e-16\n",
      "Std err: 9.861932938855693e-06\n",
      "t-value: -2875.9911504426022\n",
      "p-value: 1.166564276041105e-80\n"
     ]
    }
   ],
   "source": [
    "#第7題\n",
    "import scipy.stats as stats\n",
    "\n",
    "lr_mean = np.mean(all_lr_scores)\n",
    "svm_mean = np.mean(all_svm_scores)\n",
    "\n",
    "diff_mean = lr_mean - svm_mean\n",
    "\n",
    "lr_std = np.std(all_lr_scores, ddof=1)\n",
    "svm_std = np.std(all_svm_scores, ddof=1)\n",
    "\n",
    "n = len(all_lr_scores)\n",
    "df = n - 1\n",
    "\n",
    "std_err = np.sqrt((lr_std**2 + svm_std**2) / n)\n",
    "t = diff_mean / std_err\n",
    "p = stats.t.sf(np.abs(t), df)*2\n",
    "\n",
    "print(\"LR mean:\", lr_mean)\n",
    "print(\"SVM mean:\", svm_mean)\n",
    "print(\"Difference in means:\", diff_mean)\n",
    "\n",
    "print(\"LR std:\", lr_std)\n",
    "print(\"SVM std:\", svm_std)\n",
    "\n",
    "print(\"Std err:\", std_err)\n",
    "print(\"t-value:\", t)\n",
    "print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3a226",
   "metadata": {},
   "source": [
    "由於p-value極小，所以這兩個模型在統計上不存在顯著差異"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
